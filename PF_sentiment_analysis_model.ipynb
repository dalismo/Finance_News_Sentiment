{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PF_sentiment_analysis_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+dSNP9VWa2LtqasiUgVyh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dalismo/Finance_News_Sentiment/blob/pf%2Fpre_covid_model/PF_sentiment_analysis_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL-ei-nMDft2",
        "outputId": "ff763f6a-c0a4-47e2-ea04-98e347425ffa"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.0.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw91zJkwDkhY"
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "# spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()\n",
        "spark = SparkSession.builder.appName(\"Sentiment\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8BE_EalDr-0",
        "outputId": "d95578eb-6816-4933-ce30-d1c9fbd616d7"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/dalismo/Finance_News_Sentiment/main/Resources/sentiment.csv'\n",
        "# df = pd.read_csv(url,encoding='latin-1', header=None)\n",
        "# url =\"https://s3.amazonaws.com/dataviz-curriculum/day_2/yelp_reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"sentiment.csv\"), sep=\",\", header=None)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|     _c0|                 _c1|\n",
            "+--------+--------------------+\n",
            "|Positive|Blue Shield of Ca...|\n",
            "|Positive|RSX: Russian Equi...|\n",
            "|Positive|XLB: Hold Your Po...|\n",
            "|Positive|Musgrave Minerals...|\n",
            "|Positive|ViacomCBS to rest...|\n",
            "|Positive|Oil climbs to one...|\n",
            "|Negative|Australian regula...|\n",
            "|Positive|The Wall Street J...|\n",
            "|Positive|Ora Banda Mining ...|\n",
            "|Positive|Google Pay Plans ...|\n",
            "|Negative|Toyota, Honda Ang...|\n",
            "| Neutral|ZY Investor Alert...|\n",
            "| Neutral|Calima Energy spu...|\n",
            "|Positive|These Marijuana S...|\n",
            "|Positive|Moderna ETFs to R...|\n",
            "| Neutral|MacroGenics Annou...|\n",
            "| Neutral|Zymeworks Announc...|\n",
            "| Neutral|BioXcel Therapeut...|\n",
            "| Neutral|Merck to Present ...|\n",
            "| Neutral|BeiGene to Presen...|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0cdItleD37F",
        "outputId": "4dea0133-ba35-4e4f-cacd-5350732ae797"
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "data_df = df.withColumn('length', length(df['_c1']))\n",
        "data_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+\n",
            "|     _c0|                 _c1|length|\n",
            "+--------+--------------------+------+\n",
            "|Positive|Blue Shield of Ca...|    80|\n",
            "|Positive|RSX: Russian Equi...|    43|\n",
            "|Positive|XLB: Hold Your Po...|    23|\n",
            "|Positive|Musgrave Minerals...|   101|\n",
            "|Positive|ViacomCBS to rest...|    49|\n",
            "|Positive|Oil climbs to one...|    51|\n",
            "|Negative|Australian regula...|    67|\n",
            "|Positive|The Wall Street J...|    90|\n",
            "|Positive|Ora Banda Mining ...|    50|\n",
            "|Positive|Google Pay Plans ...|    43|\n",
            "|Negative|Toyota, Honda Ang...|    69|\n",
            "| Neutral|ZY Investor Alert...|    44|\n",
            "| Neutral|Calima Energy spu...|    58|\n",
            "|Positive|These Marijuana S...|    56|\n",
            "|Positive|Moderna ETFs to R...|    61|\n",
            "| Neutral|MacroGenics Annou...|    72|\n",
            "| Neutral|Zymeworks Announc...|   173|\n",
            "| Neutral|BioXcel Therapeut...|   130|\n",
            "| Neutral|Merck to Present ...|    80|\n",
            "| Neutral|BeiGene to Presen...|    88|\n",
            "+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeyLgISUD_QH",
        "outputId": "c818b2a5-4d87-4463-b37c-892a06101516"
      },
      "source": [
        "# Rename columns\n",
        "df1 = data_df.withColumnRenamed(\"_c0\", \"class\").withColumnRenamed(\"_c1\", \"text\")\n",
        "df1.printSchema()\n",
        "df1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- class: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- length: integer (nullable = true)\n",
            "\n",
            "+--------+--------------------+------+\n",
            "|   class|                text|length|\n",
            "+--------+--------------------+------+\n",
            "|Positive|Blue Shield of Ca...|    80|\n",
            "|Positive|RSX: Russian Equi...|    43|\n",
            "|Positive|XLB: Hold Your Po...|    23|\n",
            "|Positive|Musgrave Minerals...|   101|\n",
            "|Positive|ViacomCBS to rest...|    49|\n",
            "|Positive|Oil climbs to one...|    51|\n",
            "|Negative|Australian regula...|    67|\n",
            "|Positive|The Wall Street J...|    90|\n",
            "|Positive|Ora Banda Mining ...|    50|\n",
            "|Positive|Google Pay Plans ...|    43|\n",
            "|Negative|Toyota, Honda Ang...|    69|\n",
            "| Neutral|ZY Investor Alert...|    44|\n",
            "| Neutral|Calima Energy spu...|    58|\n",
            "|Positive|These Marijuana S...|    56|\n",
            "|Positive|Moderna ETFs to R...|    61|\n",
            "| Neutral|MacroGenics Annou...|    72|\n",
            "| Neutral|Zymeworks Announc...|   173|\n",
            "| Neutral|BioXcel Therapeut...|   130|\n",
            "| Neutral|Merck to Present ...|    80|\n",
            "| Neutral|BeiGene to Presen...|    88|\n",
            "+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuMUmwj-ELdG",
        "outputId": "c9fa9e71-ace7-4f5a-8b1b-d3ab67ba6390"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "pos_neg_to_num"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringIndexer_f56c7fa6f224"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CADJpY_qE5lM"
      },
      "source": [
        "# Tokenize DataFrame\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokenized\")\n",
        "tokenized = tokenizer.transform(df1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbyThNM0E52c",
        "outputId": "028d5753-aba8-4d96-ac58-f1959bdb8df8"
      },
      "source": [
        "# Remove stop words\n",
        "stop_list = [\"Sepp+�l+�\", \"EUR\", \".\", \"%\", \"eur\", \"mn\", \"m\", \"?\", \"$\", \"#\", \"@\"]\n",
        "stopremove = StopWordsRemover(inputCol='tokenized',outputCol='stopremove', stopWords=stop_list)\n",
        "removed_df = stopremove.transform(tokenized)\n",
        "removed_df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|class   |text                                                                                                                                                                         |length|tokenized                                                                                                                                                                                          |stopremove                                                                                                                                                                                         |\n",
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Positive|Blue Shield of California, Walgreens Partner on Personalized Healthcare Solution                                                                                             |80    |[blue, shield, of, california,, walgreens, partner, on, personalized, healthcare, solution]                                                                                                        |[blue, shield, of, california,, walgreens, partner, on, personalized, healthcare, solution]                                                                                                        |\n",
            "|Positive|RSX: Russian Equities Are Still Undervalued                                                                                                                                  |43    |[rsx:, russian, equities, are, still, undervalued]                                                                                                                                                 |[rsx:, russian, equities, are, still, undervalued]                                                                                                                                                 |\n",
            "|Positive|XLB: Hold Your Position                                                                                                                                                      |23    |[xlb:, hold, your, position]                                                                                                                                                                       |[xlb:, hold, your, position]                                                                                                                                                                       |\n",
            "|Positive|Musgrave Minerals broad, near-surface high-grade results open up further Cue gold discovery potential                                                                        |101   |[musgrave, minerals, broad,, near-surface, high-grade, results, open, up, further, cue, gold, discovery, potential]                                                                                |[musgrave, minerals, broad,, near-surface, high-grade, results, open, up, further, cue, gold, discovery, potential]                                                                                |\n",
            "|Positive|ViacomCBS to restructure Paramount Pictures - WSJ                                                                                                                            |49    |[viacomcbs, to, restructure, paramount, pictures, -, wsj]                                                                                                                                          |[viacomcbs, to, restructure, paramount, pictures, -, wsj]                                                                                                                                          |\n",
            "|Positive|Oil climbs to one-week high on U.S. supply concerns                                                                                                                          |51    |[oil, climbs, to, one-week, high, on, u.s., supply, concerns]                                                                                                                                      |[oil, climbs, to, one-week, high, on, u.s., supply, concerns]                                                                                                                                      |\n",
            "|Negative|Australian regulator denies approval for Qantas-Japan Airlines deal                                                                                                          |67    |[australian, regulator, denies, approval, for, qantas-japan, airlines, deal]                                                                                                                       |[australian, regulator, denies, approval, for, qantas-japan, airlines, deal]                                                                                                                       |\n",
            "|Positive|The Wall Street Journal: ViacomCBS revamping Paramount operations, refocusing on streaming                                                                                   |90    |[the, wall, street, journal:, viacomcbs, revamping, paramount, operations,, refocusing, on, streaming]                                                                                             |[the, wall, street, journal:, viacomcbs, revamping, paramount, operations,, refocusing, on, streaming]                                                                                             |\n",
            "|Positive|Ora Banda Mining to receive $11 million for Mt Ida                                                                                                                           |50    |[ora, banda, mining, to, receive, $11, million, for, mt, ida]                                                                                                                                      |[ora, banda, mining, to, receive, $11, million, for, mt, ida]                                                                                                                                      |\n",
            "|Positive|Google Pay Plans Israel Debut by Year's End                                                                                                                                  |43    |[google, pay, plans, israel, debut, by, year's, end]                                                                                                                                               |[google, pay, plans, israel, debut, by, year's, end]                                                                                                                                               |\n",
            "|Negative|Toyota, Honda Angry After Getting Shut Out of Electric Car Tax Credit                                                                                                        |69    |[toyota,, honda, angry, after, getting, shut, out, of, electric, car, tax, credit]                                                                                                                 |[toyota,, honda, angry, after, getting, shut, out, of, electric, car, tax, credit]                                                                                                                 |\n",
            "|Neutral |ZY Investor Alert: Shareholder Lawsuit Filed                                                                                                                                 |44    |[zy, investor, alert:, shareholder, lawsuit, filed]                                                                                                                                                |[zy, investor, alert:, shareholder, lawsuit, filed]                                                                                                                                                |\n",
            "|Neutral |Calima Energy spuds Leo #3 with fracturing just weeks away                                                                                                                   |58    |[calima, energy, spuds, leo, #3, with, fracturing, just, weeks, away]                                                                                                                              |[calima, energy, spuds, leo, #3, with, fracturing, just, weeks, away]                                                                                                                              |\n",
            "|Positive|These Marijuana Stocks May Soon Start To Recover In 2021                                                                                                                     |56    |[these, marijuana, stocks, may, soon, start, to, recover, in, 2021]                                                                                                                                |[these, marijuana, stocks, may, soon, start, to, recover, in, 2021]                                                                                                                                |\n",
            "|Positive|Moderna ETFs to Rally on Two-in-One Vaccine Booster Shot News                                                                                                                |61    |[moderna, etfs, to, rally, on, two-in-one, vaccine, booster, shot, news]                                                                                                                           |[moderna, etfs, to, rally, on, two-in-one, vaccine, booster, shot, news]                                                                                                                           |\n",
            "|Neutral |MacroGenics Announces Presentations at ESMO 2021 Virtual Annual Congress                                                                                                     |72    |[macrogenics, announces, presentations, at, esmo, 2021, virtual, annual, congress]                                                                                                                 |[macrogenics, announces, presentations, at, esmo, 2021, virtual, annual, congress]                                                                                                                 |\n",
            "|Neutral |Zymeworks Announces Abstract for Zanidatamab in First-line HER2-Expressing Gastroesophageal Cancers (GEA) at the European Society for Medical Oncology (ESMO) Annual Congress|173   |[zymeworks, announces, abstract, for, zanidatamab, in, first-line, her2-expressing, gastroesophageal, cancers, (gea), at, the, european, society, for, medical, oncology, (esmo), annual, congress]|[zymeworks, announces, abstract, for, zanidatamab, in, first-line, her2-expressing, gastroesophageal, cancers, (gea), at, the, european, society, for, medical, oncology, (esmo), annual, congress]|\n",
            "|Neutral |BioXcel Therapeutics to Present Updates from Ongoing Trial of BXCL701 in Aggressive Forms of Prostate Cancer at 2021 ESMO Congress                                           |130   |[bioxcel, therapeutics, to, present, updates, from, ongoing, trial, of, bxcl701, in, aggressive, forms, of, prostate, cancer, at, 2021, esmo, congress]                                            |[bioxcel, therapeutics, to, present, updates, from, ongoing, trial, of, bxcl701, in, aggressive, forms, of, prostate, cancer, at, 2021, esmo, congress]                                            |\n",
            "|Neutral |Merck to Present Latest Highlights From Oncology Portfolio at WCLC and ESMO 2021                                                                                             |80    |[merck, to, present, latest, highlights, from, oncology, portfolio, at, wclc, and, esmo, 2021]                                                                                                     |[merck, to, present, latest, highlights, from, oncology, portfolio, at, wclc, and, esmo, 2021]                                                                                                     |\n",
            "|Neutral |BeiGene to Present Latest Findings in Robust Lung Cancer Portfolio at ESMO Congress 2021                                                                                     |88    |[beigene, to, present, latest, findings, in, robust, lung, cancer, portfolio, at, esmo, congress, 2021]                                                                                            |[beigene, to, present, latest, findings, in, robust, lung, cancer, portfolio, at, esmo, congress, 2021]                                                                                            |\n",
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klnIXcevE5_4"
      },
      "source": [
        "# Run the hashing term frequency\n",
        "hashingTF = HashingTF(inputCol=\"stopremove\", outputCol='hash_token')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskIqZduF976"
      },
      "source": [
        "# Fit the IDF on the data set\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6eX5jQcGJSP"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FovUHSneGJv6"
      },
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K_drFBDGJ2l"
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(df1)\n",
        "cleaned = cleaner.transform(df1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzwG4j-JGPUz",
        "outputId": "a012c1fa-d7bf-4e68-cd23-8780da5109cc"
      },
      "source": [
        "# Show label and resulting features\n",
        "cleaned.select(['label', 'features']).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  1.0|(262145,[43204,50...|\n",
            "|  1.0|(262145,[31536,58...|\n",
            "|  1.0|(262145,[619,5765...|\n",
            "|  1.0|(262145,[57093,58...|\n",
            "|  1.0|(262145,[27576,38...|\n",
            "|  1.0|(262145,[15862,27...|\n",
            "|  2.0|(262145,[6993,206...|\n",
            "|  1.0|(262145,[38308,63...|\n",
            "|  1.0|(262145,[22459,27...|\n",
            "|  1.0|(262145,[66208,84...|\n",
            "|  2.0|(262145,[3091,942...|\n",
            "|  0.0|(262145,[102692,1...|\n",
            "|  0.0|(262145,[9129,233...|\n",
            "|  1.0|(262145,[16004,22...|\n",
            "|  1.0|(262145,[27576,49...|\n",
            "|  0.0|(262145,[18731,22...|\n",
            "|  0.0|(262145,[31793,45...|\n",
            "|  0.0|(262145,[1097,216...|\n",
            "|  0.0|(262145,[2690,275...|\n",
            "|  0.0|(262145,[26190,27...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYWqCBAjGPXH"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI_HG8a_GPbB",
        "outputId": "99c450c3-4a93-479a-d6bc-482d2e1a6987"
      },
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|   class|                text|length|label|           tokenized|          stopremove|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|Negative|\"Apple rejects Ep...|    72|  2.0|[\"apple, rejects,...|[\"apple, rejects,...|(262144,[15625,38...|(262144,[15625,38...|(262145,[15625,38...|[-879.68136638752...|[1.0,1.6859614660...|       0.0|\n",
            "|Negative|2 Warren Buffett ...|    51|  2.0|[2, warren, buffe...|[2, warren, buffe...|(262144,[12524,27...|(262144,[12524,27...|(262145,[12524,27...|[-656.67126235904...|[5.15520794365627...|       1.0|\n",
            "|Negative|5 Chinese Stocks ...|    54|  2.0|[5, chinese, stoc...|[5, chinese, stoc...|(262144,[89427,98...|(262144,[89427,98...|(262145,[89427,98...|[-628.01921825101...|[0.00562312028342...|       1.0|\n",
            "|Negative|AAPL Stock: Why I...|    38|  2.0|[aapl, stock:, wh...|[aapl, stock:, wh...|(262144,[30708,30...|(262144,[30708,30...|(262145,[30708,30...|[-410.46823566490...|[7.38771159830754...|       1.0|\n",
            "|Negative|AGNC Investment (...|    75|  2.0|[agnc, investment...|[agnc, investment...|(262144,[49013,50...|(262144,[49013,50...|(262145,[49013,50...|[-672.95255894190...|[1.52523118478204...|       1.0|\n",
            "|Negative|AMC Entertainment...|    76|  2.0|[amc, entertainme...|[amc, entertainme...|(262144,[10509,36...|(262144,[10509,36...|(262145,[10509,36...|[-676.95224998162...|[2.42791638657181...|       1.0|\n",
            "|Negative|AMC Entertainment...|    69|  2.0|[amc, entertainme...|[amc, entertainme...|(262144,[18697,27...|(262144,[18697,27...|(262145,[18697,27...|[-730.04808031500...|[6.53306263726710...|       1.0|\n",
            "|Negative|ASML (ASML) Dips ...|    64|  2.0|[asml, (asml), di...|[asml, (asml), di...|(262144,[49013,50...|(262144,[49013,50...|(262145,[49013,50...|[-647.18645452921...|[1.43956323606750...|       1.0|\n",
            "|Negative|AT&T (T) Dips Mor...|    61|  2.0|[at&t, (t), dips,...|[at&t, (t), dips,...|(262144,[49013,50...|(262144,[49013,50...|(262145,[49013,50...|[-620.25596861139...|[9.44428031972223...|       1.0|\n",
            "|Negative|Acreage Cannabis ...|    82|  2.0|[acreage, cannabi...|[acreage, cannabi...|(262144,[9420,434...|(262144,[9420,434...|(262145,[9420,434...|[-943.16686154983...|[1.0,6.4816910187...|       0.0|\n",
            "|Negative|Air Products and ...|    86|  2.0|[air, products, a...|[air, products, a...|(262144,[5381,252...|(262144,[5381,252...|(262145,[5381,252...|[-906.52564443868...|[7.06533344695476...|       1.0|\n",
            "|Negative|Airline stocks ra...|    77|  2.0|[airline, stocks,...|[airline, stocks,...|(262144,[89427,12...|(262144,[89427,12...|(262145,[89427,12...|[-806.46456859106...|[2.51102094004312...|       1.0|\n",
            "|Negative|Alibaba, Tencent,...|   104|  2.0|[alibaba,, tencen...|[alibaba,, tencen...|(262144,[887,5942...|(262144,[887,5942...|(262145,[887,5942...|[-1262.8002092990...|[0.03752882945149...|       1.0|\n",
            "|Negative|American Airlines...|    92|  2.0|[american, airlin...|[american, airlin...|(262144,[6993,942...|(262144,[6993,942...|(262145,[6993,942...|[-870.43839107795...|[0.99999217549818...|       0.0|\n",
            "|Negative|Apellis Pharmaceu...|    90|  2.0|[apellis, pharmac...|[apellis, pharmac...|(262144,[2677,942...|(262144,[2677,942...|(262145,[2677,942...|[-811.60110887096...|[1.0,1.1273724581...|       0.0|\n",
            "|Negative|Apple And Tesla L...|    41|  2.0|[apple, and, tesl...|[apple, and, tesl...|(262144,[76015,95...|(262144,[76015,95...|(262145,[76015,95...|[-366.05718766847...|[0.99999690335201...|       0.0|\n",
            "|Negative|Apple fires manag...|    66|  2.0|[apple, fires, ma...|[apple, fires, ma...|(262144,[9420,625...|(262144,[9420,625...|(262145,[9420,625...|[-815.86132395625...|[0.93014734014902...|       0.0|\n",
            "|Negative|Apple must allow ...|    66|  2.0|[apple, must, all...|[apple, must, all...|(262144,[29035,67...|(262144,[29035,67...|(262145,[29035,67...|[-759.20143263223...|[0.00301494935297...|       2.0|\n",
            "|Negative|Apple stock falls...|    91|  2.0|[apple, stock, fa...|[apple, stock, fa...|(262144,[18697,27...|(262144,[18697,27...|(262145,[18697,27...|[-799.87823332419...|[0.99999999999999...|       0.0|\n",
            "|Negative|Banking regulator...|    78|  2.0|[banking, regulat...|[banking, regulat...|(262144,[20618,32...|(262144,[20618,32...|(262145,[20618,32...|[-808.10422933494...|[1.0,7.4439502787...|       0.0|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiY3zhCvGPgn",
        "outputId": "9686b852-c2af-4296-bf40-5f9ad49996b6"
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.686726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLsrtFqQklC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678d719e-7b85-4df6-f132-8877db943f59"
      },
      "source": [
        "url1 = 'https://raw.githubusercontent.com/dalismo/Finance_News_Sentiment/main/Resources/pre-covid-test-data.csv'\n",
        "spark.sparkContext.addFile(url1)\n",
        "pre_covid_df = spark.read.csv(SparkFiles.get(\"pre-covid-test-data.csv\"), sep=\",\", header=None)\n",
        "\n",
        "# Show DataFrame\n",
        "pre_covid_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                 _c0|\n",
            "+--------------------+\n",
            "|Stitch Fix, Inc. ...|\n",
            "|Goldman Sachs res...|\n",
            "|What We Learned F...|\n",
            "|Cerner: A Great S...|\n",
            "|Johnson & Johnson...|\n",
            "|5 Key Conclusions...|\n",
            "|Foot Locker: Wort...|\n",
            "|The Stock Market ...|\n",
            "|These High-Yield ...|\n",
            "|This High-Yield S...|\n",
            "|New Oriental Educ...|\n",
            "|J&J to pay $20.4 ...|\n",
            "|Pharma Giant J&J ...|\n",
            "|Brokerage Stocks ...|\n",
            "|Johnson & Johnson...|\n",
            "|Visa, Mastercard ...|\n",
            "|Apple Looking For...|\n",
            "|Why Cloud Computi...|\n",
            "|Micron: Back To R...|\n",
            "|The New Ireland F...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W2OJx3HklPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8659f81-4664-419b-c704-375281aeecb8"
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "data_df1 = pre_covid_df.withColumn('length', length(pre_covid_df['_c0']))\n",
        "data_df1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+\n",
            "|                 _c0|length|\n",
            "+--------------------+------+\n",
            "|Stitch Fix, Inc. ...|    86|\n",
            "|Goldman Sachs res...|    71|\n",
            "|What We Learned F...|    56|\n",
            "|Cerner: A Great S...|    54|\n",
            "|Johnson & Johnson...|    62|\n",
            "|5 Key Conclusions...|    63|\n",
            "|Foot Locker: Wort...|    29|\n",
            "|The Stock Market ...|    63|\n",
            "|These High-Yield ...|    50|\n",
            "|This High-Yield S...|    74|\n",
            "|New Oriental Educ...|    76|\n",
            "|J&J to pay $20.4 ...|    73|\n",
            "|Pharma Giant J&J ...|    72|\n",
            "|Brokerage Stocks ...|    56|\n",
            "|Johnson & Johnson...|    66|\n",
            "|Visa, Mastercard ...|    65|\n",
            "|Apple Looking For...|    26|\n",
            "|Why Cloud Computi...|    60|\n",
            "|Micron: Back To R...|    23|\n",
            "|The New Ireland F...|    52|\n",
            "+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLsBFaXzklWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b0ec8d-bd22-4978-c004-5b65c252fd7f"
      },
      "source": [
        "# Rename columns\n",
        "df2 = data_df1.withColumnRenamed(\"_c0\", \"text\")\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- length: integer (nullable = true)\n",
            "\n",
            "+--------------------+------+\n",
            "|                text|length|\n",
            "+--------------------+------+\n",
            "|Stitch Fix, Inc. ...|    86|\n",
            "|Goldman Sachs res...|    71|\n",
            "|What We Learned F...|    56|\n",
            "|Cerner: A Great S...|    54|\n",
            "|Johnson & Johnson...|    62|\n",
            "|5 Key Conclusions...|    63|\n",
            "|Foot Locker: Wort...|    29|\n",
            "|The Stock Market ...|    63|\n",
            "|These High-Yield ...|    50|\n",
            "|This High-Yield S...|    74|\n",
            "|New Oriental Educ...|    76|\n",
            "|J&J to pay $20.4 ...|    73|\n",
            "|Pharma Giant J&J ...|    72|\n",
            "|Brokerage Stocks ...|    56|\n",
            "|Johnson & Johnson...|    66|\n",
            "|Visa, Mastercard ...|    65|\n",
            "|Apple Looking For...|    26|\n",
            "|Why Cloud Computi...|    60|\n",
            "|Micron: Back To R...|    23|\n",
            "|The New Ireland F...|    52|\n",
            "+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqzEMaJCkmRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf3fcbe4-f902-4a4b-ce0e-547fef923adc"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "pos_neg_to_num"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringIndexer_2dab5ed86bad"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNmHla4kmo5"
      },
      "source": [
        "# Tokenize DataFrame\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokenized\")\n",
        "tokenized = tokenizer.transform(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr7EPc9ekmyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706b6ea6-16b5-484a-e355-2bebe1104a46"
      },
      "source": [
        "# Remove stop words\n",
        "stop_list1 = [\"Sepp+�l+�\", \"EUR\", \".\", \"%\", \"eur\", \"mn\", \"m\", \"?\", \"$\", \"#\", \"@\"]\n",
        "stopremove1 = StopWordsRemover(inputCol='tokenized',outputCol='stopremove1', stopWords=stop_list1)\n",
        "removed_df1 = stopremove1.transform(tokenized)\n",
        "removed_df1.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------+------+------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                  |length|tokenized                                                                                             |stopremove1                                                                                           |\n",
            "+--------------------------------------------------------------------------------------+------+------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+\n",
            "|Stitch Fix, Inc. (SFIX) CEO Katrina Lake on Q4 2019 Results - Earnings Call Transcript|86    |[stitch, fix,, inc., (sfix), ceo, katrina, lake, on, q4, 2019, results, -, earnings, call, transcript]|[stitch, fix,, inc., (sfix), ceo, katrina, lake, on, q4, 2019, results, -, earnings, call, transcript]|\n",
            "|Goldman Sachs reshuffles Asia M&A leadership as John Kim retires - memo               |71    |[goldman, sachs, reshuffles, asia, m&a, leadership, as, john, kim, retires, -, memo]                  |[goldman, sachs, reshuffles, asia, m&a, leadership, as, john, kim, retires, -, memo]                  |\n",
            "|What We Learned From Amazon's Big Hardware Announcements                              |56    |[what, we, learned, from, amazon's, big, hardware, announcements]                                     |[what, we, learned, from, amazon's, big, hardware, announcements]                                     |\n",
            "|Cerner: A Great Stock To Add To Your Portfolio In 2020                                |54    |[cerner:, a, great, stock, to, add, to, your, portfolio, in, 2020]                                    |[cerner:, a, great, stock, to, add, to, your, portfolio, in, 2020]                                    |\n",
            "|Johnson & Johnson settles Ohio lawsuits to avoid federal trial                        |62    |[johnson, &, johnson, settles, ohio, lawsuits, to, avoid, federal, trial]                             |[johnson, &, johnson, settles, ohio, lawsuits, to, avoid, federal, trial]                             |\n",
            "|5 Key Conclusions From United Technologies' Latest Presentation                       |63    |[5, key, conclusions, from, united, technologies', latest, presentation]                              |[5, key, conclusions, from, united, technologies', latest, presentation]                              |\n",
            "|Foot Locker: Worth The Gamble                                                         |29    |[foot, locker:, worth, the, gamble]                                                                   |[foot, locker:, worth, the, gamble]                                                                   |\n",
            "|The Stock Market Dived Today, but These 2 Stocks Blasted Higher                       |63    |[the, stock, market, dived, today,, but, these, 2, stocks, blasted, higher]                           |[the, stock, market, dived, today,, but, these, 2, stocks, blasted, higher]                           |\n",
            "|These High-Yield Stocks Are Adding to Their Appeal                                    |50    |[these, high-yield, stocks, are, adding, to, their, appeal]                                           |[these, high-yield, stocks, are, adding, to, their, appeal]                                           |\n",
            "|This High-Yield Stock Could Generate Massive Returns Over the Next 5 Years            |74    |[this, high-yield, stock, could, generate, massive, returns, over, the, next, 5, years]               |[this, high-yield, stock, could, generate, massive, returns, over, the, next, 5, years]               |\n",
            "|New Oriental Education Sees Recurring Revenues and Multi-Generational Demand          |76    |[new, oriental, education, sees, recurring, revenues, and, multi-generational, demand]                |[new, oriental, education, sees, recurring, revenues, and, multi-generational, demand]                |\n",
            "|J&J to pay $20.4 million to settle opioid lawsuits with two Ohio counties             |73    |[j&j, to, pay, $20.4, million, to, settle, opioid, lawsuits, with, two, ohio, counties]               |[j&j, to, pay, $20.4, million, to, settle, opioid, lawsuits, with, two, ohio, counties]               |\n",
            "|Pharma Giant J&J Avoids Opioid Trial In Ohio With $10 Million Settlement              |72    |[pharma, giant, j&j, avoids, opioid, trial, in, ohio, with, $10, million, settlement]                 |[pharma, giant, j&j, avoids, opioid, trial, in, ohio, with, $10, million, settlement]                 |\n",
            "|Brokerage Stocks Plunge As Schwab Eliminates Commissions                              |56    |[brokerage, stocks, plunge, as, schwab, eliminates, commissions]                                      |[brokerage, stocks, plunge, as, schwab, eliminates, commissions]                                      |\n",
            "|Johnson & Johnson settles with Ohio counties ahead of opioid trial                    |66    |[johnson, &, johnson, settles, with, ohio, counties, ahead, of, opioid, trial]                        |[johnson, &, johnson, settles, with, ohio, counties, ahead, of, opioid, trial]                        |\n",
            "|Visa, Mastercard reconsider backing Facebook's Libra, report says                     |65    |[visa,, mastercard, reconsider, backing, facebook's, libra,, report, says]                            |[visa,, mastercard, reconsider, backing, facebook's, libra,, report, says]                            |\n",
            "|Apple Looking For New High                                                            |26    |[apple, looking, for, new, high]                                                                      |[apple, looking, for, new, high]                                                                      |\n",
            "|Why Cloud Computing Will be a Key Revenue Driver for Alibaba                          |60    |[why, cloud, computing, will, be, a, key, revenue, driver, for, alibaba]                              |[why, cloud, computing, will, be, a, key, revenue, driver, for, alibaba]                              |\n",
            "|Micron: Back To Reality                                                               |23    |[micron:, back, to, reality]                                                                          |[micron:, back, to, reality]                                                                          |\n",
            "|The New Ireland Fund, Inc. Monthly Portfolio Update.                                  |52    |[the, new, ireland, fund,, inc., monthly, portfolio, update.]                                         |[the, new, ireland, fund,, inc., monthly, portfolio, update.]                                         |\n",
            "+--------------------------------------------------------------------------------------+------+------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbgiVF2eknAm"
      },
      "source": [
        "# Run the hashing term frequency\n",
        "hashingTF1 = HashingTF(inputCol=\"stopremove1\", outputCol='hash_token1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIVt_uQllweP"
      },
      "source": [
        "# Fit the IDF on the data set\n",
        "idf1 = IDF(inputCol='hash_token1', outputCol='idf_token1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8wNAw2Tlwlv"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up1 = VectorAssembler(inputCols=['idf_token1', 'length'], outputCol='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tbKw6umlwql"
      },
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline1 = Pipeline(stages=[tokenizer, stopremove1, hashingTF1, idf1, clean_up1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vCDhQAllwwf"
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner1 = data_prep_pipeline1.fit(df2)\n",
        "cleaned1 = cleaner.transform(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEsxcgItmHW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f337a16a-f4fc-4cb5-f1bc-af1880ed5dd2"
      },
      "source": [
        "# Show label and resulting features\n",
        "cleaned1.select(['features']).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|(262145,[6012,339...|\n",
            "|(262145,[17470,17...|\n",
            "|(262145,[32108,81...|\n",
            "|(262145,[18697,27...|\n",
            "|(262145,[2162,397...|\n",
            "|(262145,[101169,1...|\n",
            "|(262145,[44541,51...|\n",
            "|(262145,[8145,125...|\n",
            "|(262145,[22575,27...|\n",
            "|(262145,[18697,54...|\n",
            "|(262145,[70835,83...|\n",
            "|(262145,[3973,266...|\n",
            "|(262145,[2162,340...|\n",
            "|(262145,[31462,89...|\n",
            "|(262145,[2162,504...|\n",
            "|(262145,[8981,283...|\n",
            "|(262145,[89833,10...|\n",
            "|(262145,[5835,403...|\n",
            "|(262145,[27576,51...|\n",
            "|(262145,[27506,89...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOwo7YIm0NaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e2e2280-4db1-4372-925e-c3be3d3b5d87"
      },
      "source": [
        "from pyspark.sql.functions import lit\n",
        "cleaned2 = cleaned1.withColumn(\"label\", lit(0))\n",
        "cleaned2.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|                text|length|           tokenized|          stopremove|          hash_token|           idf_token|            features|label|\n",
            "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|Stitch Fix, Inc. ...|    86|[stitch, fix,, in...|[stitch, fix,, in...|(262144,[6012,339...|(262144,[6012,339...|(262145,[6012,339...|    0|\n",
            "|Goldman Sachs res...|    71|[goldman, sachs, ...|[goldman, sachs, ...|(262144,[17470,17...|(262144,[17470,17...|(262145,[17470,17...|    0|\n",
            "|What We Learned F...|    56|[what, we, learne...|[what, we, learne...|(262144,[32108,81...|(262144,[32108,81...|(262145,[32108,81...|    0|\n",
            "|Cerner: A Great S...|    54|[cerner:, a, grea...|[cerner:, a, grea...|(262144,[18697,27...|(262144,[18697,27...|(262145,[18697,27...|    0|\n",
            "|Johnson & Johnson...|    62|[johnson, &, john...|[johnson, &, john...|(262144,[2162,397...|(262144,[2162,397...|(262145,[2162,397...|    0|\n",
            "|5 Key Conclusions...|    63|[5, key, conclusi...|[5, key, conclusi...|(262144,[101169,1...|(262144,[101169,1...|(262145,[101169,1...|    0|\n",
            "|Foot Locker: Wort...|    29|[foot, locker:, w...|[foot, locker:, w...|(262144,[44541,51...|(262144,[44541,51...|(262145,[44541,51...|    0|\n",
            "|The Stock Market ...|    63|[the, stock, mark...|[the, stock, mark...|(262144,[8145,125...|(262144,[8145,125...|(262145,[8145,125...|    0|\n",
            "|These High-Yield ...|    50|[these, high-yiel...|[these, high-yiel...|(262144,[22575,27...|(262144,[22575,27...|(262145,[22575,27...|    0|\n",
            "|This High-Yield S...|    74|[this, high-yield...|[this, high-yield...|(262144,[18697,54...|(262144,[18697,54...|(262145,[18697,54...|    0|\n",
            "|New Oriental Educ...|    76|[new, oriental, e...|[new, oriental, e...|(262144,[70835,83...|(262144,[70835,83...|(262145,[70835,83...|    0|\n",
            "|J&J to pay $20.4 ...|    73|[j&j, to, pay, $2...|[j&j, to, pay, $2...|(262144,[3973,266...|(262144,[3973,266...|(262145,[3973,266...|    0|\n",
            "|Pharma Giant J&J ...|    72|[pharma, giant, j...|[pharma, giant, j...|(262144,[2162,340...|(262144,[2162,340...|(262145,[2162,340...|    0|\n",
            "|Brokerage Stocks ...|    56|[brokerage, stock...|[brokerage, stock...|(262144,[31462,89...|(262144,[31462,89...|(262145,[31462,89...|    0|\n",
            "|Johnson & Johnson...|    66|[johnson, &, john...|[johnson, &, john...|(262144,[2162,504...|(262144,[2162,504...|(262145,[2162,504...|    0|\n",
            "|Visa, Mastercard ...|    65|[visa,, mastercar...|[visa,, mastercar...|(262144,[8981,283...|(262144,[8981,283...|(262145,[8981,283...|    0|\n",
            "|Apple Looking For...|    26|[apple, looking, ...|[apple, looking, ...|(262144,[89833,10...|(262144,[89833,10...|(262145,[89833,10...|    0|\n",
            "|Why Cloud Computi...|    60|[why, cloud, comp...|[why, cloud, comp...|(262144,[5835,403...|(262144,[5835,403...|(262145,[5835,403...|    0|\n",
            "|Micron: Back To R...|    23|[micron:, back, t...|[micron:, back, t...|(262144,[27576,51...|(262144,[27576,51...|(262145,[27576,51...|    0|\n",
            "|The New Ireland F...|    52|[the, new, irelan...|[the, new, irelan...|(262144,[27506,89...|(262144,[27506,89...|(262145,[27506,89...|    0|\n",
            "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJtkSG90mHbd"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned2.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "# predictor = nb.fit(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKUDy0w5mHfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3536443c-d40d-4b23-dfdb-7f87cce39593"
      },
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results1 = predictor.transform(testing)\n",
        "test_results1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "|                text|length|           tokenized|          stopremove|          hash_token|           idf_token|            features|label|       rawPrediction|         probability|prediction|\n",
            "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "|\"Comcast Says Cor...|    86|[\"comcast, says, ...|[\"comcast, says, ...|(262144,[12274,27...|(262144,[12274,27...|(262145,[12274,27...|    0|[-947.49803609039...|[0.90622427338317...|       0.0|\n",
            "|   \"How \"\"Buy Online|    17|[\"how, \"\"buy, onl...|[\"how, \"\"buy, onl...|(262144,[50671,79...|(262144,[50671,79...|(262145,[50671,79...|    0|[-299.91137245314...|[0.98312346313230...|       0.0|\n",
            "|\"Smart Timing for...|    98|[\"smart, timing, ...|[\"smart, timing, ...|(262144,[7655,451...|(262144,[7655,451...|(262145,[7655,451...|    0|[-1206.7647526758...|[0.00420013656909...|       1.0|\n",
            "|\"This Transition ...|   105|[\"this, transitio...|[\"this, transitio...|(262144,[12250,48...|(262144,[12250,48...|(262145,[12250,48...|    0|[-1072.5011870224...|[0.99999835874352...|       0.0|\n",
            "|'Boycott Uber' Tr...|    68|['boycott, uber',...|['boycott, uber',...|(262144,[9420,697...|(262144,[9420,697...|(262145,[9420,697...|    0|[-868.89312496202...|[0.99999794574885...|       0.0|\n",
            "|'Bull's-eye' land...|    72|['bull's-eye', la...|['bull's-eye', la...|(262144,[10326,84...|(262144,[10326,84...|(262145,[10326,84...|    0|[-910.43037893317...|[1.0,5.0072782912...|       0.0|\n",
            "|'Designed by clow...|    84|['designed, by, c...|['designed, by, c...|(262144,[17596,18...|(262144,[17596,18...|(262145,[17596,18...|    0|[-1134.1509153663...|[0.99999974789480...|       0.0|\n",
            "|'Everyone is all ...|    74|['everyone, is, a...|['everyone, is, a...|(262144,[11025,38...|(262144,[11025,38...|(262145,[11025,38...|    0|[-792.53611997866...|[1.0,3.5334997975...|       0.0|\n",
            "|'Everything Apple...|    87|['everything, app...|['everything, app...|(262144,[27283,58...|(262144,[27283,58...|(262145,[27283,58...|    0|[-998.73377222223...|[0.99729911248473...|       0.0|\n",
            "|'Hellish conditio...|    67|['hellish, condit...|['hellish, condit...|(262144,[20848,75...|(262144,[20848,75...|(262145,[20848,75...|    0|[-809.26178138199...|[0.99975540805667...|       0.0|\n",
            "|'I'm a believer i...|    72|['i'm, a, believe...|['i'm, a, believe...|(262144,[2002,186...|(262144,[2002,186...|(262145,[2002,186...|    0|[-832.60524206731...|[0.99999999984587...|       0.0|\n",
            "|'Invest In Oil No...|    96|['invest, in, oil...|['invest, in, oil...|(262144,[528,1903...|(262144,[528,1903...|(262145,[528,1903...|    0|[-1425.5455454667...|[1.41108342020688...|       1.0|\n",
            "|'Irrationally Bul...|    51|['irrationally, b...|['irrationally, b...|(262144,[23083,25...|(262144,[23083,25...|(262145,[23083,25...|    0|[-552.81099451849...|[0.99999959367291...|       0.0|\n",
            "|'Jedi mind-tricki...|    43|['jedi, mind-tric...|['jedi, mind-tric...|(262144,[10706,12...|(262144,[10706,12...|(262145,[10706,12...|    0|[-604.35468629169...|[0.99905886339918...|       0.0|\n",
            "|1 Analyst Thinks ...|    64|[1, analyst, thin...|[1, analyst, thin...|(262144,[27576,30...|(262144,[27576,30...|(262145,[27576,30...|    0|[-746.03381525195...|[2.37724443599430...|       1.0|\n",
            "|1 Cannabis Stock ...|    38|[1, cannabis, sto...|[1, cannabis, sto...|(262144,[18697,27...|(262144,[18697,27...|(262145,[18697,27...|    0|[-411.07895357187...|[0.88051287647048...|       0.0|\n",
            "|1 Top High-Yield ...|    50|[1, top, high-yie...|[1, top, high-yie...|(262144,[3283,181...|(262144,[3283,181...|(262145,[3283,181...|    0|[-429.99760467220...|[1.57488343600957...|       1.0|\n",
            "|1-800 FLOWERS.COM...|    93|[1-800, flowers.c...|[1-800, flowers.c...|(262144,[20964,37...|(262144,[20964,37...|(262145,[20964,37...|    0|[-961.59211267694...|[1.0,2.0513015665...|       0.0|\n",
            "|10x Genomics, Inc...|    88|[10x, genomics,, ...|[10x, genomics,, ...|(262144,[29435,38...|(262144,[29435,38...|(262145,[29435,38...|    0|[-971.18672422997...|[1.0,4.5178274128...|       0.0|\n",
            "|12 Stocks That Ha...|    58|[12, stocks, that...|[12, stocks, that...|(262144,[48448,89...|(262144,[48448,89...|(262145,[48448,89...|    0|[-624.53195068576...|[0.88271440441728...|       0.0|\n",
            "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGSLu5W8mHj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05e4225-39d5-45ca-f840-81a6ac80fe95"
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval1 = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval1.evaluate(test_results1)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.807133\n"
          ]
        }
      ]
    }
  ]
}